{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/benotti/diplodatos2020/blob/master/Practico_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BYWMIumxlaT-"
   },
   "source": [
    "# Aprendizaje no supervisado\n",
    "\n",
    "Este es el último práctico de la diplomatura. En este práctico se espera que puedan poner en práctica los conocimientos adquiridos en el curso de Aprendizaje No Supervisado, trabajando con el conjunto de datos de la mentoría. La metodología de seguimiento y entrega será la misma que para los prácticos anteriores. La fecha final de entrega será el 4/10.\n",
    "\n",
    "El objetivo es que se apliquen las siguientes dos técnicas no supervisadas: clustering y word embeddings. En el conjunto de datos tenemos el atributo de etiqueta o clase pero para este práctico sólo usaremos dicho atributo al evaluar el modelo.\n",
    "\n",
    "Se espera que hagan uso de las herramientas vistas en el curso y que investiguen sobre word embeddings usando las referencias dadas en este práctico. Se espera que hagan uso especialmente de las herramientas brindadas por `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sG6wGKfXlaUh"
   },
   "source": [
    "## Ejercicio 1: Descripción de los Datos y la Tarea\n",
    "\n",
    "Responder las siguientes preguntas *sin mirar* el resto del práctico:\n",
    "\n",
    "0. Ir a leer 15 ejemplos de diálogos clasificados de forma negativa y 5 positivos y copiar palabras, frases o describir otras características que les llamaron la atención en los diálogos negativos.\n",
    "1. ¿Qué esperan ver en los clusters de palabras? \n",
    "2. ¿Cómo les parece que se evaluará el modelo que generen?\n",
    "3. ¿Cuál les parece que debe ser la duración mínima de un diálogo para poder predecir la satisfacción del estudiante? ¿Piensan que la duración del diálogo les puede servir para predecir la satisfacción?\n",
    "4. Del primer cuarto, segundo cuarto, tercer cuarto y cuarto cuarto de los diálogos, ¿cuál les parece que puede ser más informativo para predecir la satisfacción del estudiante?\n",
    "5. El modelo que tienen en mente ¿están seguros que no usa las etiquetas hasta el final?\n",
    "\n",
    "**No es necesario escribir código para responder estas preguntas.**\n",
    "\n",
    "[Desarrollo de la consigna 1](Practico_5_desarrollo/Practico_5_part_1.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_gg2_ms4laUk"
   },
   "source": [
    "## Ejercicio 2: Graficar grupos en dos ejes\n",
    "\n",
    "En este ejercicio se solicita realizar un gráfico de todos los diálogos en el dataset completo en el cual se represente a los diálogos con calificación positiva con un punto de un color y a los de calificación negativa con otro color. El eje *x* será la duración del diálogo en cantidad de turnos y el eje *y* serán la cantidad de caracteres escritos por el estudiante en ese diálogo dividido la cantidad de turnos del estudiante para ese diálogo (es decir, el promedio de cantidad de caracteres por turno del estudiante para el diálogo). ¿Ven grupos en el gráfico en alguno de los dos ejes?   \n",
    "\n",
    "[Desarrollo de la consigna 2](Practico_5_desarrollo/Practico_5_part_2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZyE4xAknBpce"
   },
   "source": [
    "## Ejercicio 3: Cargar y explorar word embeddings pre-entrenados \n",
    "\n",
    "En este ejercicio cargarán y explorarán word embeddings preentrenados, les recomiendo Glove usando la función most_similar y variando el valor de topn. Un tutorial sobre cómo hacerlo pueden encontrarse acá:\n",
    "\n",
    "https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "\n",
    "Mostrar ejemplos usando most_similar que les resulten interesantes.\n",
    "\n",
    "[Desarrollo de la consigna 3](Practico_5_desarrollo/Practico_5_part_3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yY_iJ95flaUr"
   },
   "source": [
    "## Ejercicio 4: Entrenar word embeddings \n",
    "\n",
    "En este ejercicio entrenarán word embeddings usando el dataset de la mentoría ¿Con qué fragmento del dataset entrenarán? ¿Y los stop-words?. Un tutorial sobre cómo hacerlo pueden encontrarse acá:\n",
    "\n",
    "https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "\n",
    "Otra opción es usar fasttext, que es un poco diferente a word2vec pero para nuestros objetivos también estaría bien. Acá hay un tutorial de fasttext https://fasttext.cc/docs/en/unsupervised-tutorial.html. Si usan fasttext la visualización se hace a través de la función nn (nearest neighbours) (se pueden ver ejemplos en el link). \n",
    "\n",
    "*Sugiero que este ejercicio lo haga Juan que tiene acceso a los servidores del CCAD*\n",
    "\n",
    "[Desarrollo de la consigna 4](Practico_5_desarrollo/Practico_5_part_4.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oN8E5khGBVUk"
   },
   "source": [
    "## Ejercicio 5: Visualizar los word embeddings que uds entrenaron\n",
    "\n",
    "En este ejercicio aprenderán como visualizar word embeddings de algunos tokens usando PCA (por ejemplo los emoticones, o palabras que uds creen se asociarán a diálogos positivos como \"thanks!\"). Un tutorial sobre cómo hacerlo pueden encontrarse acá usando gensim:\n",
    "\n",
    "https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "\n",
    "No se olviden de tener bien claro cuál es el vocabulario. Recuerden imprimir la cantidad de palabras del vocabulario frecuentemente y de visualizar la primeras 50. \n",
    "\n",
    "Opcional: comparar la visualización de emoticones o \"thank\" \"thanks\" y similares entre Glove y los word-embeddings que uds entrenaron. \n",
    "\n",
    "[Desarrollo de la consigna 5](Practico_5_desarrollo/Practico_5_part_5.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9tByYJGOFjgI"
   },
   "source": [
    "## Ejercicio 6: Clustering \n",
    "\n",
    "6.1) Ahora usaremos un algoritmos de clustering como k-means a los word-embeddings de un diálogo. Una estrategia sencilla para calcular el word-embedding de un diálogo es sumar todos los word embeddings de las palabras del diálogo y dividirlas por la cantidad de palabras del diálogo. Naturalmente usaríamos 2 clusters porque es una clasificación binaria. ¿Tendría sentido usar 3 clusters o más?\n",
    "\n",
    "6.2) Repetir lo mismo pero usando sólo el ultimo 25% del diálogo (los ultimos turnos).   \n",
    "\n",
    "6.3) Evaluar la distribución de los diálogos positivos y negativos en clusters. \n",
    "\n",
    "Aquí encontrarán qué métodos y librerías pueden ser útiles para la implementación: https://ai.intelligentonlinetools.com/ml/k-means-clustering-example-word2vec/. Para k-means les recomiendo usar scikit-learn como describe el link. \n",
    "\n",
    "[Desarrollo de la consigna 6](Practico_5_desarrollo/Practico_5_part_6_a.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Practico_3y4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
